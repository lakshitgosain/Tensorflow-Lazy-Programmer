{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOj1U4Qz17kEKGY8WGRb1Uv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshitgosain/Tensorflow-Lazy-Programmer/blob/main/Tensorflow_Lazy_Programmer_Section_3(Classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JiNI4ZdC6IVC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M2ajxh9r6Shw",
        "outputId": "92f64ac2-131e-4446-abfd-1135e4cdf07a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer #Loading the Data"
      ],
      "metadata": {
        "id": "m8WZl52E6Tlm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=load_breast_cancer()"
      ],
      "metadata": {
        "id": "1Z5382T_7BA6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhcUlRGA7HnD",
        "outputId": "568f1211-bb94-4d2f-9d74-1c1a1405335d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHUP55DS7WPr",
        "outputId": "c0b51c01-286e-45c6-f14e-f2e877647541"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXR5sdEx7KX2",
        "outputId": "e283ac62-9910-4680-9176-ff7ba7a7b418"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaDR-ug67f2o",
        "outputId": "97945cd1-fcf3-4993-f2cc-96e6d3c30de3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.target_names#0->Malignant, 1->benign"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELXQqXiE7sAC",
        "outputId": "e760b7b9-2b6c-439f-cf39-cf57a2551c16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfEJFHaQ74u5",
        "outputId": "5dde464f-537a-4294-b8e2-b96342f15b50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame(data.data, columns=data.feature_names)"
      ],
      "metadata": {
        "id": "_peK0-l781qu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "SuhPSA_e9AIY",
        "outputId": "f351319c-bc85-4dff-80fa-fc99ed930900"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1b1adc4-5212-4da5-8162-793efbefa640\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1b1adc4-5212-4da5-8162-793efbefa640')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1b1adc4-5212-4da5-8162-793efbefa640 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1b1adc4-5212-4da5-8162-793efbefa640');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Z86r_2Ga9JCZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(data.data,data.target,test_size=0.33)"
      ],
      "metadata": {
        "id": "H7cd5nhl9SWa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N, D =X_train.shape"
      ],
      "metadata": {
        "id": "FHAM6yIB9kxW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N,D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gWfGpjoUQOY",
        "outputId": "bfe44563-99d6-40e1-c0f1-79cfd2351762"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(381, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler  # Give it 0 Mean and Variance 1"
      ],
      "metadata": {
        "id": "NdXug5dwURb-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar=StandardScaler()\n",
        "X_train=scalar.fit_transform(X_train)\n",
        "X_test=scalar.transform(X_test) #We fit on train set as it is going to find the parameters"
      ],
      "metadata": {
        "id": "15qJodEHUZvl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(D,)),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "7Z3BlWP7VYH1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alternative way. Create the equential model and add layers later on\n",
        "#model=tf.keras.models.Sequential()\n",
        "#model.add(tf.keras.layers.Dense())"
      ],
      "metadata": {
        "id": "KtxAoC6NV4qb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "G72JfRK9WIqV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r=model.fit(\n",
        "    X_train,y_train,\n",
        "    validation_data=(X_test,y_test),\n",
        "    epochs=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIydmffPWgmu",
        "outputId": "9b86a7f7-0533-4c90-de3b-425e2e9fc993"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 4s 121ms/step - loss: 0.8995 - accuracy: 0.3858 - val_loss: 0.8185 - val_accuracy: 0.4840\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8141 - accuracy: 0.4462 - val_loss: 0.7436 - val_accuracy: 0.5319\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.7402 - accuracy: 0.5223 - val_loss: 0.6759 - val_accuracy: 0.6011\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6762 - accuracy: 0.5958 - val_loss: 0.6156 - val_accuracy: 0.6755\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6190 - accuracy: 0.6588 - val_loss: 0.5643 - val_accuracy: 0.7181\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5713 - accuracy: 0.7008 - val_loss: 0.5199 - val_accuracy: 0.7979\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.5298 - accuracy: 0.7323 - val_loss: 0.4819 - val_accuracy: 0.8085\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4945 - accuracy: 0.7848 - val_loss: 0.4491 - val_accuracy: 0.8457\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7953 - val_loss: 0.4202 - val_accuracy: 0.8564\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8136 - val_loss: 0.3954 - val_accuracy: 0.8830\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4150 - accuracy: 0.8399 - val_loss: 0.3736 - val_accuracy: 0.8936\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3948 - accuracy: 0.8425 - val_loss: 0.3540 - val_accuracy: 0.9096\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8451 - val_loss: 0.3367 - val_accuracy: 0.9096\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3604 - accuracy: 0.8504 - val_loss: 0.3213 - val_accuracy: 0.9202\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3452 - accuracy: 0.8609 - val_loss: 0.3077 - val_accuracy: 0.9255\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3319 - accuracy: 0.8714 - val_loss: 0.2951 - val_accuracy: 0.9362\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3194 - accuracy: 0.8819 - val_loss: 0.2839 - val_accuracy: 0.9415\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3081 - accuracy: 0.8871 - val_loss: 0.2737 - val_accuracy: 0.9468\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2977 - accuracy: 0.8924 - val_loss: 0.2643 - val_accuracy: 0.9468\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2878 - accuracy: 0.9003 - val_loss: 0.2558 - val_accuracy: 0.9468\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2787 - accuracy: 0.9003 - val_loss: 0.2479 - val_accuracy: 0.9415\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2704 - accuracy: 0.9055 - val_loss: 0.2407 - val_accuracy: 0.9468\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2625 - accuracy: 0.9134 - val_loss: 0.2340 - val_accuracy: 0.9468\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2551 - accuracy: 0.9239 - val_loss: 0.2277 - val_accuracy: 0.9468\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2484 - accuracy: 0.9213 - val_loss: 0.2218 - val_accuracy: 0.9468\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2417 - accuracy: 0.9265 - val_loss: 0.2165 - val_accuracy: 0.9468\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2357 - accuracy: 0.9265 - val_loss: 0.2114 - val_accuracy: 0.9468\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2300 - accuracy: 0.9344 - val_loss: 0.2067 - val_accuracy: 0.9468\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2245 - accuracy: 0.9370 - val_loss: 0.2022 - val_accuracy: 0.9468\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2194 - accuracy: 0.9370 - val_loss: 0.1981 - val_accuracy: 0.9468\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2146 - accuracy: 0.9396 - val_loss: 0.1941 - val_accuracy: 0.9468\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2099 - accuracy: 0.9396 - val_loss: 0.1904 - val_accuracy: 0.9468\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2056 - accuracy: 0.9396 - val_loss: 0.1869 - val_accuracy: 0.9521\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2015 - accuracy: 0.9449 - val_loss: 0.1835 - val_accuracy: 0.9521\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.1976 - accuracy: 0.9501 - val_loss: 0.1803 - val_accuracy: 0.9628\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1937 - accuracy: 0.9501 - val_loss: 0.1774 - val_accuracy: 0.9628\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9528 - val_loss: 0.1745 - val_accuracy: 0.9628\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.1868 - accuracy: 0.9554 - val_loss: 0.1718 - val_accuracy: 0.9628\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1835 - accuracy: 0.9580 - val_loss: 0.1693 - val_accuracy: 0.9681\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1804 - accuracy: 0.9580 - val_loss: 0.1668 - val_accuracy: 0.9681\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1774 - accuracy: 0.9580 - val_loss: 0.1644 - val_accuracy: 0.9681\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1745 - accuracy: 0.9580 - val_loss: 0.1622 - val_accuracy: 0.9681\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1717 - accuracy: 0.9580 - val_loss: 0.1600 - val_accuracy: 0.9681\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1691 - accuracy: 0.9580 - val_loss: 0.1580 - val_accuracy: 0.9681\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1666 - accuracy: 0.9606 - val_loss: 0.1560 - val_accuracy: 0.9681\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1641 - accuracy: 0.9606 - val_loss: 0.1541 - val_accuracy: 0.9681\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1617 - accuracy: 0.9606 - val_loss: 0.1524 - val_accuracy: 0.9681\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1595 - accuracy: 0.9606 - val_loss: 0.1506 - val_accuracy: 0.9681\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1573 - accuracy: 0.9606 - val_loss: 0.1489 - val_accuracy: 0.9681\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.9606 - val_loss: 0.1473 - val_accuracy: 0.9681\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1531 - accuracy: 0.9633 - val_loss: 0.1458 - val_accuracy: 0.9681\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1512 - accuracy: 0.9633 - val_loss: 0.1443 - val_accuracy: 0.9628\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1493 - accuracy: 0.9633 - val_loss: 0.1429 - val_accuracy: 0.9628\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1474 - accuracy: 0.9659 - val_loss: 0.1415 - val_accuracy: 0.9628\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1457 - accuracy: 0.9659 - val_loss: 0.1401 - val_accuracy: 0.9628\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1440 - accuracy: 0.9659 - val_loss: 0.1389 - val_accuracy: 0.9628\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.1423 - accuracy: 0.9659 - val_loss: 0.1376 - val_accuracy: 0.9681\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1407 - accuracy: 0.9659 - val_loss: 0.1364 - val_accuracy: 0.9681\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1391 - accuracy: 0.9659 - val_loss: 0.1353 - val_accuracy: 0.9681\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1377 - accuracy: 0.9685 - val_loss: 0.1342 - val_accuracy: 0.9681\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1362 - accuracy: 0.9685 - val_loss: 0.1331 - val_accuracy: 0.9681\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1347 - accuracy: 0.9685 - val_loss: 0.1320 - val_accuracy: 0.9681\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1333 - accuracy: 0.9711 - val_loss: 0.1310 - val_accuracy: 0.9681\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1320 - accuracy: 0.9738 - val_loss: 0.1300 - val_accuracy: 0.9681\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1306 - accuracy: 0.9738 - val_loss: 0.1291 - val_accuracy: 0.9734\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1294 - accuracy: 0.9738 - val_loss: 0.1281 - val_accuracy: 0.9734\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1281 - accuracy: 0.9738 - val_loss: 0.1273 - val_accuracy: 0.9734\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1269 - accuracy: 0.9738 - val_loss: 0.1264 - val_accuracy: 0.9734\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1257 - accuracy: 0.9764 - val_loss: 0.1256 - val_accuracy: 0.9734\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1246 - accuracy: 0.9764 - val_loss: 0.1248 - val_accuracy: 0.9734\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1235 - accuracy: 0.9764 - val_loss: 0.1239 - val_accuracy: 0.9734\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1224 - accuracy: 0.9764 - val_loss: 0.1232 - val_accuracy: 0.9734\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1213 - accuracy: 0.9764 - val_loss: 0.1224 - val_accuracy: 0.9734\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1203 - accuracy: 0.9764 - val_loss: 0.1217 - val_accuracy: 0.9734\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1192 - accuracy: 0.9764 - val_loss: 0.1210 - val_accuracy: 0.9734\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.9764 - val_loss: 0.1203 - val_accuracy: 0.9734\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.9764 - val_loss: 0.1196 - val_accuracy: 0.9734\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.9764 - val_loss: 0.1190 - val_accuracy: 0.9734\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1154 - accuracy: 0.9764 - val_loss: 0.1183 - val_accuracy: 0.9734\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1145 - accuracy: 0.9764 - val_loss: 0.1177 - val_accuracy: 0.9734\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1136 - accuracy: 0.9764 - val_loss: 0.1171 - val_accuracy: 0.9734\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1127 - accuracy: 0.9764 - val_loss: 0.1165 - val_accuracy: 0.9734\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1118 - accuracy: 0.9764 - val_loss: 0.1159 - val_accuracy: 0.9734\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1110 - accuracy: 0.9764 - val_loss: 0.1153 - val_accuracy: 0.9734\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.1102 - accuracy: 0.9764 - val_loss: 0.1148 - val_accuracy: 0.9734\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1094 - accuracy: 0.9764 - val_loss: 0.1143 - val_accuracy: 0.9734\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1086 - accuracy: 0.9764 - val_loss: 0.1137 - val_accuracy: 0.9734\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1079 - accuracy: 0.9790 - val_loss: 0.1132 - val_accuracy: 0.9734\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.1071 - accuracy: 0.9790 - val_loss: 0.1127 - val_accuracy: 0.9734\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1064 - accuracy: 0.9790 - val_loss: 0.1122 - val_accuracy: 0.9734\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1056 - accuracy: 0.9790 - val_loss: 0.1118 - val_accuracy: 0.9734\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1049 - accuracy: 0.9790 - val_loss: 0.1113 - val_accuracy: 0.9734\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1042 - accuracy: 0.9790 - val_loss: 0.1108 - val_accuracy: 0.9734\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.1035 - accuracy: 0.9790 - val_loss: 0.1104 - val_accuracy: 0.9734\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.1029 - accuracy: 0.9790 - val_loss: 0.1100 - val_accuracy: 0.9734\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1022 - accuracy: 0.9790 - val_loss: 0.1095 - val_accuracy: 0.9734\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.1016 - accuracy: 0.9790 - val_loss: 0.1091 - val_accuracy: 0.9734\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1009 - accuracy: 0.9790 - val_loss: 0.1087 - val_accuracy: 0.9734\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1003 - accuracy: 0.9790 - val_loss: 0.1083 - val_accuracy: 0.9734\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0997 - accuracy: 0.9790 - val_loss: 0.1079 - val_accuracy: 0.9734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train_Score: \",model.evaluate(X_train,y_train))\n",
        "print(\"Test_Score: \",model.evaluate(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeX9CSCuWt7n",
        "outputId": "13a4311f-fa25-4048-efa9-16f3b61e5ba0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0993 - accuracy: 0.9790\n",
            "Train_Score:  [0.09929828345775604, 0.9790025949478149]\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9734\n",
            "Test_Score:  [0.10793187469244003, 0.9734042286872864]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the Loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['loss'],label='loss')\n",
        "plt.plot(r.history['val_loss'],label='val_loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HCbDsQuFXPtQ",
        "outputId": "62d6c2e7-8445-47b7-945c-1f9d75959ed8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6e770fbdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['accuracy'],label='accuracy')\n",
        "plt.plot(r.history['val_accuracy'],label='val_accuracy')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "zD8bivj9XvF7",
        "outputId": "6c2d2462-0bcd-481f-8b22-9f608f4e9d5c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xtz77_8pX7Au"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2 - Making Predictions ##"
      ],
      "metadata": {
        "id": "bAOgMn4u1cL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P=model.predict(X_test)"
      ],
      "metadata": {
        "id": "WJ_zHxmH1eTt",
        "outputId": "ff79a6a3-d59e-43c7-bd91-d58dd89d0d0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(P)"
      ],
      "metadata": {
        "id": "id5RJDQz1hiY",
        "outputId": "b092d72a-d4e3-4f0a-f4ca-e33e11af460c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.46304739e-01]\n",
            " [7.72198558e-01]\n",
            " [3.11903586e-03]\n",
            " [9.54804897e-01]\n",
            " [9.97798562e-01]\n",
            " [1.32774905e-04]\n",
            " [8.58001411e-01]\n",
            " [9.94848669e-01]\n",
            " [1.41352462e-02]\n",
            " [9.97069955e-01]\n",
            " [1.34892098e-03]\n",
            " [8.32783103e-01]\n",
            " [9.39820886e-01]\n",
            " [9.52372253e-01]\n",
            " [9.24923122e-01]\n",
            " [9.71322298e-01]\n",
            " [7.37524152e-01]\n",
            " [6.59949728e-04]\n",
            " [2.11364865e-01]\n",
            " [1.55215002e-05]\n",
            " [8.24895740e-01]\n",
            " [8.71822059e-01]\n",
            " [1.21695049e-01]\n",
            " [9.53423321e-01]\n",
            " [1.24609442e-02]\n",
            " [5.37688613e-01]\n",
            " [9.87696826e-01]\n",
            " [9.79384065e-01]\n",
            " [9.71547902e-01]\n",
            " [9.47443068e-01]\n",
            " [9.05976221e-02]\n",
            " [1.15068851e-03]\n",
            " [9.99826431e-01]\n",
            " [9.95781720e-01]\n",
            " [8.89812171e-01]\n",
            " [9.96113479e-01]\n",
            " [9.88607645e-01]\n",
            " [4.64383274e-01]\n",
            " [9.33529556e-01]\n",
            " [8.39790165e-01]\n",
            " [9.96819139e-01]\n",
            " [2.02172045e-02]\n",
            " [9.28571761e-01]\n",
            " [9.52505231e-01]\n",
            " [9.99107480e-01]\n",
            " [9.73738432e-01]\n",
            " [1.56902603e-03]\n",
            " [3.90621983e-02]\n",
            " [1.12697831e-04]\n",
            " [9.03363526e-03]\n",
            " [9.83391285e-01]\n",
            " [9.99287903e-01]\n",
            " [6.08142093e-03]\n",
            " [9.78026986e-01]\n",
            " [9.73940432e-01]\n",
            " [1.51492143e-03]\n",
            " [7.97596574e-03]\n",
            " [9.92644727e-01]\n",
            " [4.27583568e-02]\n",
            " [7.64878392e-01]\n",
            " [9.61808443e-01]\n",
            " [4.62428783e-04]\n",
            " [4.65286151e-03]\n",
            " [9.81594920e-01]\n",
            " [9.78663206e-01]\n",
            " [3.12382244e-02]\n",
            " [8.59844446e-01]\n",
            " [9.96297121e-01]\n",
            " [4.34449874e-02]\n",
            " [8.33177030e-01]\n",
            " [9.84722435e-01]\n",
            " [9.56805646e-01]\n",
            " [6.03333600e-02]\n",
            " [3.46345070e-04]\n",
            " [6.75165236e-01]\n",
            " [4.73193973e-01]\n",
            " [9.97984111e-01]\n",
            " [5.83059201e-03]\n",
            " [9.99674082e-01]\n",
            " [9.86194968e-01]\n",
            " [2.21405085e-03]\n",
            " [1.75123885e-02]\n",
            " [3.61502916e-03]\n",
            " [5.36374003e-02]\n",
            " [1.39661517e-03]\n",
            " [9.95581865e-01]\n",
            " [9.98316169e-01]\n",
            " [9.89636064e-01]\n",
            " [9.99428332e-01]\n",
            " [1.56357570e-03]\n",
            " [1.48251384e-01]\n",
            " [6.61955953e-01]\n",
            " [1.11459427e-01]\n",
            " [9.80242789e-01]\n",
            " [9.77494001e-01]\n",
            " [4.41746935e-02]\n",
            " [1.54777870e-01]\n",
            " [9.95210707e-01]\n",
            " [9.98408556e-01]\n",
            " [9.48590457e-01]\n",
            " [8.81484151e-03]\n",
            " [9.96062577e-01]\n",
            " [9.67135012e-01]\n",
            " [9.32875276e-01]\n",
            " [2.74694022e-02]\n",
            " [9.87402558e-01]\n",
            " [9.87031937e-01]\n",
            " [8.62214446e-01]\n",
            " [9.80623066e-01]\n",
            " [9.79543865e-01]\n",
            " [9.06668603e-01]\n",
            " [4.34983260e-04]\n",
            " [9.68762875e-01]\n",
            " [7.93125749e-01]\n",
            " [2.11180001e-01]\n",
            " [9.51608300e-01]\n",
            " [1.65554836e-01]\n",
            " [9.91775870e-01]\n",
            " [5.54831745e-03]\n",
            " [9.94602859e-01]\n",
            " [9.40548480e-01]\n",
            " [9.12032008e-01]\n",
            " [1.29405230e-01]\n",
            " [9.90989923e-01]\n",
            " [4.60791737e-02]\n",
            " [9.19215322e-01]\n",
            " [1.17739382e-05]\n",
            " [9.34930265e-01]\n",
            " [8.56603265e-01]\n",
            " [9.83825982e-01]\n",
            " [6.05445681e-03]\n",
            " [9.75752354e-01]\n",
            " [9.81117606e-01]\n",
            " [9.00461435e-01]\n",
            " [1.68213442e-01]\n",
            " [5.64477127e-03]\n",
            " [9.59139645e-01]\n",
            " [3.61642279e-02]\n",
            " [7.20004380e-01]\n",
            " [9.99662399e-01]\n",
            " [1.02785736e-04]\n",
            " [8.40637147e-01]\n",
            " [9.44737434e-01]\n",
            " [8.35060835e-01]\n",
            " [9.74632263e-01]\n",
            " [1.52205065e-01]\n",
            " [5.80626205e-02]\n",
            " [9.88187075e-01]\n",
            " [9.77633238e-01]\n",
            " [2.01774500e-02]\n",
            " [9.99009967e-01]\n",
            " [1.21982638e-02]\n",
            " [9.83425200e-01]\n",
            " [9.98034656e-01]\n",
            " [1.97659321e-02]\n",
            " [9.98885751e-01]\n",
            " [9.85105813e-01]\n",
            " [9.94025588e-01]\n",
            " [9.99035120e-01]\n",
            " [9.75232601e-01]\n",
            " [5.66265546e-02]\n",
            " [9.94996011e-01]\n",
            " [2.25179717e-02]\n",
            " [6.89655244e-01]\n",
            " [9.86236513e-01]\n",
            " [1.10893243e-03]\n",
            " [9.94084418e-01]\n",
            " [9.09024596e-01]\n",
            " [2.01401303e-06]\n",
            " [9.29505050e-01]\n",
            " [3.70961934e-01]\n",
            " [9.79979098e-01]\n",
            " [4.09699737e-07]\n",
            " [9.02165413e-01]\n",
            " [9.93691325e-01]\n",
            " [8.96538973e-01]\n",
            " [9.88545299e-01]\n",
            " [3.07217182e-04]\n",
            " [3.71776164e-01]\n",
            " [9.57519174e-01]\n",
            " [9.96900558e-01]\n",
            " [9.67786014e-01]\n",
            " [9.96564388e-01]\n",
            " [9.94383216e-01]\n",
            " [8.98620725e-01]\n",
            " [5.07513214e-05]\n",
            " [2.22272381e-01]\n",
            " [2.12200712e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We need to round these probabilities to get the actual poredictions\n",
        "#NOTE: has to be flattened since the targets are size(N,) while the predictions are size(N,1)"
      ],
      "metadata": {
        "id": "O9vAabmp1i-a"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "P=np.round(P).flatten()"
      ],
      "metadata": {
        "id": "SYm7XdCt1xXY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(P)"
      ],
      "metadata": {
        "id": "w7vxr0jp12mn",
        "outputId": "996a261e-e269-40e8-e643-1942e8f56d0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1.\n",
            " 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculcate the accuracy, compaer it to evaulate() output\n",
        "print('Manually Calcualted accuracy', np.mean(P==y_test))\n",
        "print('Evaluate Output', model.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "id": "3fgxmQdp15kk",
        "outputId": "fceea554-ae27-43ca-b53c-9b636b5876fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually Calcualted accuracy 0.973404255319149\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9734\n",
            "Evaluate Output [0.10793187469244003, 0.9734042286872864]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4P5uyvtx2Xbf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}